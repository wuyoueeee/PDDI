
# ğŸŒ¿ åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©ç—…è™«å®³æ£€æµ‹ç³»ç»Ÿ (PDDI - Plant Disease Detection and Identification)


## é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©ç—…è™«å®³æ£€æµ‹ç³»ç»Ÿï¼Œä½¿ç”¨YOLOv8ç›®æ ‡æ£€æµ‹æ¨¡å‹å®ç°å¯¹æ¤ç‰©ç—…è™«å®³çš„å®æ—¶æ£€æµ‹å’Œè¯†åˆ«ã€‚ç³»ç»Ÿæä¾›äº†å‹å¥½çš„Webç•Œé¢ï¼Œæ”¯æŒæ¨¡å‹è®­ç»ƒã€æµ‹è¯•å’Œå®æ—¶æ£€æµ‹ç­‰åŠŸèƒ½ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/f3038ff64c444fcea1721f1352262c4f.png)

ä»£ç è·å–ï¼š[https://mbd.pub/o/bread/mbd-YZWVlJ1qZw==](https://mbd.pub/o/bread/mbd-YZWVlJ1qZw==)
è§†é¢‘ä»‹ç»ï¼š
[video(video-lNKCLjpM-1751909124371)(type-bilibili)(url-https://player.bilibili.com/player.html?aid=114813082542067)(image-https://i-blog.csdnimg.cn/img_convert/880df815daf1e59112d1b1c74361a341.jpeg)(title-åŸºäºæ·±åº¦å­¦ä¹ çš„æ¤ç‰©ç—…è™«å®³æ£€æµ‹ç³»ç»Ÿ(å«UIç•Œé¢ã€YOLOæ¨¡å‹ã€ä»£ç ã€æ•°æ®é›†))]

### ç³»ç»ŸåŠŸèƒ½
- ğŸŒŸ å®æ—¶ç—…è™«å®³æ£€æµ‹ä¸è¯†åˆ«
- ğŸ“Š å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ç›‘æ§
- ğŸ“ˆ è¯¦ç»†çš„æ¨¡å‹è¯„ä¼°æŠ¥å‘Š
- ğŸ”„ æ”¯æŒæ¨¡å‹å¾®è°ƒå’Œä¼˜åŒ–
- ğŸ’» ç›´è§‚çš„Webæ“ä½œç•Œé¢
- ğŸ“± å“åº”å¼è®¾è®¡ï¼Œæ”¯æŒå¤šè®¾å¤‡è®¿é—®

## ç¯å¢ƒè¦æ±‚
### åŸºæœ¬è¦æ±‚
- Python 3.8+
- CUDA 11.0+ (GPUè®­ç»ƒå¯é€‰)
- 8GB+ RAM
### æ¨èé…ç½®
- NVIDIA GPU (8GB+ æ˜¾å­˜)
- 16GB+ RAM
- SSDå­˜å‚¨

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. ç¯å¢ƒæ£€æŸ¥
è¿è¡ŒGPUç¯å¢ƒæ£€æµ‹å·¥å…·ç¡®è®¤ç³»ç»ŸçŠ¶æ€ï¼š
```bash
python check_gpu.py
```

### 3. æ•°æ®å‡†å¤‡
è¿è¡Œæ•°æ®é›†å‡†å¤‡å·¥å…·ï¼š
```bash
python prepare_dataset.py
```

### 4. å¯åŠ¨ç³»ç»Ÿ
```bash
streamlit run app.py
```

## é¡¹ç›®ç»“æ„
```
PDDI/
â”œâ”€â”€ app.py                 # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ modules/               # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ training.py       # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ testing.py        # æµ‹è¯•æ¨¡å—
â”‚   â””â”€â”€ detection.py      # æ£€æµ‹æ¨¡å—
â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ prepare_dataset.py # æ•°æ®é›†å¤„ç†
â”‚   â”œâ”€â”€ check_gpu.py      # GPUæ£€æŸ¥
â”‚   â””â”€â”€ metrics.py        # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ dataset/              # æ•°æ®é›†ç›®å½•
â”œâ”€â”€ models/               # æ¨¡å‹å­˜å‚¨
â””â”€â”€ configs/              # é…ç½®æ–‡ä»¶
```

## æ ¸å¿ƒæ¨¡å—

### ä¸»ç¨‹åº (app.py)
ä¸»ç¨‹åºè´Ÿè´£æ•´ä¸ªåº”ç”¨çš„åˆå§‹åŒ–å’Œé¡µé¢è·¯ç”±ï¼Œä½¿ç”¨Streamlitæ„å»ºWebç•Œé¢ã€‚ä¸»è¦åŠŸèƒ½ï¼š
- é¡µé¢é…ç½®å’Œåˆå§‹åŒ–
- å¯¼èˆªèœå•ç®¡ç†
- åŠŸèƒ½æ¨¡å—é›†æˆ
- ç”¨æˆ·äº¤äº’å¤„ç†

### è®­ç»ƒæ¨¡å— (modules/training.py)
è®­ç»ƒæ¨¡å—è´Ÿè´£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ç®¡ç†ï¼š
- è®­ç»ƒå‚æ•°é…ç½®
- è®­ç»ƒè¿‡ç¨‹ç›‘æ§
- è®­ç»ƒç»“æœå¯è§†åŒ–
- æ¨¡å‹ä¿å­˜ç®¡ç†
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/a4c3f77065214bfd92e5b447d8812bbc.png)
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/38ecfbc18eae422ab86cef9f785e6173.png)

### æµ‹è¯•æ¨¡å— (modules/testing.py)
æµ‹è¯•æ¨¡å—è´Ÿè´£æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼š
- å‡†ç¡®ç‡è®¡ç®—
- æ··æ·†çŸ©é˜µç”Ÿæˆ
- æµ‹è¯•æŠ¥å‘Šè¾“å‡º
- æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/060861b522bb43c689adf608fffda17e.png)

### æ£€æµ‹æ¨¡å— (modules/detection.py)
æ£€æµ‹æ¨¡å—è´Ÿè´£å®é™…çš„ç—…è™«å®³æ£€æµ‹ï¼š
- å›¾åƒé¢„å¤„ç†
- æ¨¡å‹æ¨ç†
- ç»“æœåå¤„ç†
- å¯è§†åŒ–å±•ç¤º
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/ab83d0d8473348a19534d6c4c4dd7d9a.png)
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/ff2c965bdd2044f587e2373434496295.png)

## æ•°æ®å¤„ç†

### æ•°æ®é›†è¯´æ˜
æœ¬é¡¹ç›®ä½¿ç”¨æ”¹è¿›çš„PlantVillageæ•°æ®é›†ï¼š
- æ•°æ®è§„æ¨¡ï¼š54,000+ å›¾åƒ
- ä½œç‰©ç§ç±»ï¼š14ç§
- ç—…å®³ç±»åˆ«ï¼š38ç§
- å›¾åƒåˆ†è¾¨ç‡ï¼š256x256åƒç´ 

### æ•°æ®å¤„ç†å·¥å…· (prepare_dataset.py)
```python
class DatasetPreparation:
    def __init__(self, source_dir, target_dir):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.train_ratio = 0.8
        self.val_ratio = 0.1
        self.test_ratio = 0.1
```
ä¸»è¦åŠŸèƒ½ï¼š
- æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
- æ•°æ®é›†åˆ’åˆ†
- æ ‡æ³¨æ–‡ä»¶ç”Ÿæˆ
- é…ç½®æ–‡ä»¶ç”Ÿæˆ

### ç¯å¢ƒæ£€æµ‹å·¥å…· (check_gpu.py)
```python
class GPUChecker:
    def __init__(self):
        self.cuda_available = torch.cuda.is_available()
        self.gpu_info = self.get_gpu_info()
```
ä¸»è¦åŠŸèƒ½ï¼š
- CUDAç¯å¢ƒæ£€æŸ¥
- GPUä¿¡æ¯è·å–
- ç³»ç»Ÿå…¼å®¹æ€§éªŒè¯
- æ€§èƒ½è¯„ä¼°

## æ¨¡å‹è®­ç»ƒ

### è®­ç»ƒé…ç½®
- åŸºç¡€å‚æ•°ï¼š
  * è®­ç»ƒè½®æ¬¡ï¼š100
  * æ‰¹æ¬¡å¤§å°ï¼š16
  * å›¾ç‰‡å°ºå¯¸ï¼š640
  * å­¦ä¹ ç‡ï¼š0.01
  * é¢„çƒ­è½®æ¬¡ï¼š3

### è®­ç»ƒæµç¨‹
1. å‡†å¤‡æ•°æ®é›†
2. é…ç½®è®­ç»ƒå‚æ•°
3. å¯åŠ¨è®­ç»ƒä»»åŠ¡
4. ç›‘æ§è®­ç»ƒè¿›åº¦
5. è¯„ä¼°è®­ç»ƒç»“æœ

### è®­ç»ƒç›‘æ§
- å®æ—¶æŸå¤±æ›²çº¿
- å‡†ç¡®ç‡æŒ‡æ ‡
- èµ„æºå ç”¨
- è®­ç»ƒæ—¥å¿—

## éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
# å¯åŠ¨åº”ç”¨
streamlit run app.py
```

## å¸¸è§é—®é¢˜

### GPUç›¸å…³
1. GPUä¸å¯ç”¨ï¼Ÿ
   - æ£€æŸ¥CUDAå®‰è£…
   - æ›´æ–°æ˜¾å¡é©±åŠ¨
   - ç¡®è®¤CUDAç‰ˆæœ¬å…¼å®¹æ€§

2. è®­ç»ƒé€Ÿåº¦æ…¢ï¼Ÿ
   - è°ƒæ•´æ‰¹æ¬¡å¤§å°
   - ä½¿ç”¨GPUè®­ç»ƒ
   - ä¼˜åŒ–æ•°æ®åŠ è½½

3. æ£€æµ‹å‡†ç¡®ç‡ä½ï¼Ÿ
   - å¢åŠ è®­ç»ƒæ•°æ®
   - è°ƒæ•´æ¨¡å‹å‚æ•°
   - ä½¿ç”¨æ•°æ®å¢å¼º

## æ ¸å¿ƒä»£ç è¯´æ˜

### 1. æ¨¡å‹è®­ç»ƒæ ¸å¿ƒä»£ç 

```python
# modules/training.py

class TrainingPage:
    def __init__(self):
        self.setup_directories()
        self.load_last_training()
        
    def train_model(self, params):
        """æ¨¡å‹è®­ç»ƒä¸»å‡½æ•°"""
        try:
            # åˆå§‹åŒ–æ¨¡å‹
            model = YOLO('yolov8n.pt' if params['pretrained'] else 'yolov8n.yaml')
            
            # é…ç½®è®­ç»ƒå‚æ•°
            train_args = {
                'data': 'dataset/data.yaml',      # æ•°æ®é›†é…ç½®
                'epochs': params['epochs'],        # è®­ç»ƒè½®æ¬¡
                'batch': params['batch_size'],     # æ‰¹æ¬¡å¤§å°
                'imgsz': params['img_size'],       # å›¾ç‰‡å°ºå¯¸
                'device': params['device'],        # è®­ç»ƒè®¾å¤‡
                'workers': params['num_workers'],  # æ•°æ®åŠ è½½çº¿ç¨‹
                'lr0': params['learning_rate'],    # åˆå§‹å­¦ä¹ ç‡
                'momentum': params['momentum'],    # åŠ¨é‡
                'weight_decay': params['weight_decay'],  # æƒé‡è¡°å‡
                'warmup_epochs': params['warmup_epochs'],  # é¢„çƒ­è½®æ¬¡
                'project': 'runs/train',           # è¾“å‡ºç›®å½•
                'name': f'exp_{datetime.now().strftime("%Y%m%d_%H%M%S")}'  # å®éªŒåç§°
            }
            
            # å¼€å§‹è®­ç»ƒ
            results = model.train(**train_args)
            
            # ä¿å­˜è®­ç»ƒç»“æœ
            self.save_training_results(results)
            return True
            
        except Exception as e:
            st.error(f"è®­ç»ƒé”™è¯¯: {str(e)}")
            return False
            
    def plot_training_metrics(self, results_file):
        """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡å›¾è¡¨"""
        results_df = pd.read_csv(results_file)
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(results_df['epoch'], results_df['train/box_loss'], label='å®šä½æŸå¤±')
        ax1.plot(results_df['epoch'], results_df['train/cls_loss'], label='åˆ†ç±»æŸå¤±')
        ax1.set_title('è®­ç»ƒæŸå¤±æ›²çº¿')
        ax1.set_xlabel('è®­ç»ƒè½®æ¬¡')
        ax1.set_ylabel('æŸå¤±å€¼')
        ax1.legend()
        
        # è¯„ä¼°æŒ‡æ ‡æ›²çº¿
        ax2.plot(results_df['epoch'], results_df['metrics/precision(B)'], label='å‡†ç¡®ç‡')
        ax2.plot(results_df['epoch'], results_df['metrics/recall(B)'], label='å¬å›ç‡')
        ax2.plot(results_df['epoch'], results_df['metrics/mAP50(B)'], label='mAP@0.5')
        ax2.set_title('è¯„ä¼°æŒ‡æ ‡æ›²çº¿')
        ax2.set_xlabel('è®­ç»ƒè½®æ¬¡')
        ax2.set_ylabel('æŒ‡æ ‡å€¼')
        ax2.legend()
        
        return fig
```

### 2. æ¨¡å‹æµ‹è¯•æ ¸å¿ƒä»£ç 

```python
# modules/testing.py

class TestingPage:
    def __init__(self):
        self.load_model()
        self.setup_metrics()
    
    def evaluate_model(self, test_loader):
        """æ¨¡å‹è¯„ä¼°å‡½æ•°"""
        results = []
        metrics = {
            'precision': 0,
            'recall': 0,
            'mAP50': 0,
            'mAP50-95': 0
        }
        
        # æ‰¹é‡æµ‹è¯•
        for batch in test_loader:
            # æ¨¡å‹é¢„æµ‹
            pred = self.model(batch['images'])
            
            # è®¡ç®—æ‰¹æ¬¡æŒ‡æ ‡
            batch_metrics = self.calculate_metrics(pred, batch['labels'])
            self.update_metrics(metrics, batch_metrics)
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            results.extend(self.process_predictions(pred, batch))
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        report = self.generate_report(results, metrics)
        return report
    
    def calculate_metrics(self, predictions, targets):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        # è®¡ç®—IOU
        iou = box_iou(predictions[:, :4], targets[:, :4])
        
        # è®¡ç®—TP, FP, FN
        correct = iou > 0.5
        tp = correct.sum().float()
        fp = (~correct).sum().float()
        fn = (targets.shape[0] - tp)
        
        # è®¡ç®—precisionå’Œrecall
        precision = tp / (tp + fp + 1e-16)
        recall = tp / (tp + fn + 1e-16)
        
        return {
            'precision': precision.item(),
            'recall': recall.item(),
            'tp': tp.item(),
            'fp': fp.item(),
            'fn': fn.item()
        }
```

### 3. æ£€æµ‹æ¨¡å—æ ¸å¿ƒä»£ç 

```python
# modules/detection.py

class DetectionPage:
    def __init__(self):
        self.load_model()
        self.setup_interface()
    
    def process_image(self, image):
        """å›¾åƒå¤„ç†å’Œæ£€æµ‹"""
        try:
            # å›¾åƒé¢„å¤„ç†
            processed_img = self.preprocess_image(image)
            
            # æ‰§è¡Œæ£€æµ‹
            results = self.model(processed_img)
            
            # åå¤„ç†ç»“æœ
            detections = self.postprocess_results(results)
            
            return detections
        except Exception as e:
            st.error(f"æ£€æµ‹é”™è¯¯: {str(e)}")
            return None
    
    def preprocess_image(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        # è°ƒæ•´å›¾åƒå¤§å°
        resized = cv2.resize(image, (640, 640))
        
        # å½’ä¸€åŒ–
        normalized = resized.astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸ºå¼ é‡
        tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
        
        return tensor
    
    def postprocess_results(self, results):
        """æ£€æµ‹ç»“æœåå¤„ç†"""
        detections = []
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹æ¡†
        for det in results.pred[0]:
            x1, y1, x2, y2, conf, cls = det
            
            detection = {
                'bbox': [x1.item(), y1.item(), x2.item(), y2.item()],
                'confidence': conf.item(),
                'class_id': int(cls.item()),
                'class_name': self.class_names[int(cls.item())]
            }
            
            detections.append(detection)
        
        return detections
    
    def visualize_results(self, image, detections):
        """ç»“æœå¯è§†åŒ–"""
        # å¤åˆ¶å›¾åƒä»¥é¿å…ä¿®æ”¹åŸå›¾
        vis_image = image.copy()
        
        # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹æ¡†
        for det in detections:
            # è·å–è¾¹ç•Œæ¡†åæ ‡
            x1, y1, x2, y2 = det['bbox']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(vis_image, 
                         (int(x1), int(y1)), 
                         (int(x2), int(y2)),
                         (0, 255, 0), 2)
            
            # æ·»åŠ æ ‡ç­¾
            label = f"{det['class_name']} {det['confidence']:.2f}"
            cv2.putText(vis_image, label,
                       (int(x1), int(y1) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       0.5, (0, 255, 0), 2)
        
        return vis_image
```

### 4. æ•°æ®å¤„ç†å·¥å…·æ ¸å¿ƒä»£ç 

```python
# utils/data_processing.py

class DataProcessor:
    def __init__(self):
        self.augmentation_config = self.load_config()
    
    def preprocess_dataset(self, dataset_path):
        """æ•°æ®é›†é¢„å¤„ç†"""
        # å›¾åƒæ ‡å‡†åŒ–
        normalized_images = self.normalize_images(dataset_path)
        
        # æ•°æ®å¢å¼º
        augmented_images = self.apply_augmentation(normalized_images)
        
        # ç”Ÿæˆæ ‡ç­¾
        self.generate_labels(augmented_images)
    
    def apply_augmentation(self, images):
        """åº”ç”¨æ•°æ®å¢å¼º"""
        augmented = []
        
        for img in images:
            # éšæœºæ°´å¹³ç¿»è½¬
            if random.random() > 0.5:
                img = cv2.flip(img, 1)
            
            # éšæœºäº®åº¦è°ƒæ•´
            if random.random() > 0.5:
                factor = random.uniform(0.5, 1.5)
                img = cv2.convertScaleAbs(img, alpha=factor, beta=0)
            
            # éšæœºæ—‹è½¬
            if random.random() > 0.5:
                angle = random.uniform(-15, 15)
                h, w = img.shape[:2]
                M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
                img = cv2.warpAffine(img, M, (w, h))
            
            augmented.append(img)
        
        return augmented
```

è¿™äº›æ ¸å¿ƒä»£ç å±•ç¤ºäº†ç³»ç»Ÿçš„ä¸»è¦åŠŸèƒ½å®ç°ï¼ŒåŒ…æ‹¬ï¼š
1. æ¨¡å‹è®­ç»ƒæµç¨‹å’Œå‚æ•°é…ç½®
2. æ¨¡å‹è¯„ä¼°å’ŒæŒ‡æ ‡è®¡ç®—
3. å›¾åƒæ£€æµ‹å’Œç»“æœå¯è§†åŒ–
4. æ•°æ®é¢„å¤„ç†å’Œå¢å¼ºæ–¹æ³•

æ¯ä¸ªæ¨¡å—éƒ½åŒ…å«äº†è¯¦ç»†çš„æ³¨é‡Šï¼Œæ–¹ä¾¿ç”¨æˆ·ç†è§£ä»£ç åŠŸèƒ½å’Œå®ç°é€»è¾‘ã€‚
